seed: -1
torch_deterministic: True

origin_shape: 31 #env origin
proprioception_shape: 21  #proprio 
encoded_observation_shape: 37 # encoded = proprio + latent
latent_shape: 16
PCDownSampleNum: 8192
TDownSampleNum: 64

rl_algo: "sac"
rl_iter: 2800

policy: # only works for MlpPolicy right now
  hidden_nodes: 512
  hidden_layer: 3
  activation: elu # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid

student: # only works for MlpPolicy right now
  pi_hid_sizes: [512, 512,512]
  activation: elu # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid
  
learn:
  test: False
  resume: 0
  save_interval: 600 # check for potential saves every this many iterations
  print_log: True

  # rollout params
  max_iterations: 800000

  # training params
  cliprange: 0.2
  ent_coef: 0
  nsteps: 8
  noptepochs: 5
  nminibatches: 4 # this is per agent
  max_grad_norm: 1
  optim_stepsize: 3.e-4 # 3e-4 is default for single agent training with constant schedule
 

  log_interval: 1
  asymmetric: False
